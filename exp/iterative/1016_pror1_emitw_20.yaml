# full supervision, segthor heart
data:
  dataset: BGDataset
  dataname: Prostate
  anisotropy: True   # True if (max_spacing/min_spacing>3)
  data_dir: '/group/lishl/weak_datasets/Promise12/1011_train_weak_percent_0.1_random/expand_mat/'
  use_weak: True   # Dice and CE loss
  em_save_pseudo_dir: '/group/lishl/weak_exp/em_save_pseudo/'   # save dir of train_set pseudo labels in EM

model:
  network: 'Generic_UNet'
  pool_op_kernel_sizes: '[(1, 2, 2), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)]'   # (8, 32, 32)
  conv_kernel_sizes: '[(1, 3, 3), (1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)]'
  use_finetune: True
  finetune_model_path: '/group/lishl/weak_exp/checkpoints_li/1012_pro_r1_02/best_model.pth'
  finetune_model_path_ae: '/group/lishl/weak_exp/checkpoints_li/1013_pro_aelo_18/best_model.pth'
  use_emiter: True  # iterative EM forward
  iterate_epoch: 0  # iterate per epoch rather than per iteration, {1, 10, 30}
  fpr_drop_freq: 0  # the frequency of fp_filter_ratio dropping (in epochs)
  filter_phase:  'probae'
  fp_filter_ratio: 0.5
  fn_filter_ratio: 2.0

train:
  n_epochs: 500 #100
  n_batches: 250  #250
  train_batch: 2 #4
  valid_batch: 1 #4

  pseudo_one_supervision: True
  pseudo_loss_weight: 10  # loss: weak + pseudo * weight
  weak_loss_weight:   0.1
  loss_name: 'MultipleOutputLoss2' #'CEDiceLoss'  #
  with_dice_loss: 0
  fg_weight: 1  #16
  auto_weight_fg_bg: True
  draw_fgbg: False

  optimizer: SGD    # Adam
  momentum: 0.99
  lr: 1.0e-2
  lr_decay: 'constant'  #'plateau'